{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jl9bAf7clY9S"
      },
      "source": [
        "### Install Import and Prepare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XfNCLBJ4mIvD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\bashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\bashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\bashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\bashi\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\bashi\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
            "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install -q transformers accelerate nltk\n",
        "\n",
        "import json\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "# Download NLTK data\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')  # Additional download needed for newer NLTK versions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 465 entries from the dataset\n",
            "Sample entries:\n",
            "Entry 1: ['answer', 'question', 'question_text', 'tags', 'url']\n",
            "Question: is it fine to exercise with knee pain?\n",
            "Answer: from your description it appears that you may have anterior knee pain which sometimes presents as pa...\n",
            "---\n",
            "Entry 2: ['answer', 'question', 'question_text', 'tags', 'url']\n",
            "Question: suffering from anxiety restlessness and taking clonazepam & mirtazapine. i had depression & panic attacks for the last 7 years. need a second opinion.\n",
            "Answer: depression anxiety restlessness and panic attacks are best respond to a combination of a selective s...\n",
            "---\n",
            "\n",
            "Prepared 20 Q&A pairs for evaluation\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# Load the dataset from the local JSON file\n",
        "json_file_path = r\"c:\\Users\\bashi\\Downloads\\icliniqQAs.json\"\n",
        "\n",
        "# Check if file exists\n",
        "if not os.path.exists(json_file_path):\n",
        "    print(f\"File not found: {json_file_path}\")\n",
        "    print(\"Please make sure the icliniqQAs.json file is in the correct location.\")\n",
        "else:\n",
        "    with open(json_file_path, \"r\", encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    print(f\"Loaded {len(data)} entries from the dataset\")\n",
        "    \n",
        "    # Check the structure of the first few entries\n",
        "    print(\"Sample entries:\")\n",
        "    for i, entry in enumerate(data[:2]):\n",
        "        print(f\"Entry {i+1}: {list(entry.keys())}\")\n",
        "        print(f\"Question: {entry['question']}\")\n",
        "        print(f\"Answer: {entry['answer'][:100]}...\")  # Show first 100 chars\n",
        "        print(\"---\")\n",
        "\n",
        "# Prepare QA pairs for testing (use first 20 for quick evaluation)\n",
        "qa_samples = [\n",
        "    {\n",
        "        'question': entry['question'],\n",
        "        'answer': entry['answer']\n",
        "    }\n",
        "    for entry in data[:20]  # Use first 20 entries\n",
        "]\n",
        "\n",
        "print(f\"\\nPrepared {len(qa_samples)} Q&A pairs for evaluation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model: gpt2\n",
            "This model doesn't require authentication and should work out of the box.\n",
            "Note: For better medical QA performance, you'd want to use Llama 3.2 with proper HF authentication.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\bashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\bashi\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully!\n",
            "Model device: cpu\n",
            "CUDA available: False\n",
            "Model parameters: 124,439,808\n",
            "\n",
            "============================================================\n",
            "To use Llama 3.2 (recommended for better performance):\n",
            "1. Create a Hugging Face account at https://huggingface.co/\n",
            "2. Request access to the Llama 3.2 model\n",
            "3. Install huggingface_hub: pip install huggingface_hub\n",
            "4. Login: huggingface-cli login\n",
            "5. Then change model_name to 'meta-llama/Llama-3.2-1B'\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model_options = [\n",
        "    (\"microsoft/DialoGPT-medium\", \"DialoGPT Medium - Good for conversational AI\"),\n",
        "    (\"gpt2\", \"GPT-2 - Classic generative model\"),\n",
        "    (\"distilgpt2\", \"DistilGPT-2 - Smaller and faster version of GPT-2\"),\n",
        "    (\"microsoft/DialoGPT-small\", \"DialoGPT Small - Faster but smaller model\")\n",
        "]\n",
        "\n",
        "# Let's use GPT-2 as it's reliable and doesn't require authentication\n",
        "model_name = \"gpt2\"\n",
        "\n",
        "print(f\"Loading model: {model_name}\")\n",
        "print(\"This model doesn't require authentication and should work out of the box.\")\n",
        "print(\"Note: For better medical QA performance, you'd want to use Llama 3.2 with proper HF authentication.\")\n",
        "\n",
        "try:\n",
        "    # Load tokenizer and model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    \n",
        "    # Set pad token if not available\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "    \n",
        "    # Load model with appropriate settings\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name, \n",
        "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "        device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "        low_cpu_mem_usage=True\n",
        "    )\n",
        "    \n",
        "    print(f\"Model loaded successfully!\")\n",
        "    print(f\"Model device: {next(model.parameters()).device}\")\n",
        "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    print(\"You may need to:\")\n",
        "    print(\"1. Install torch with CUDA support if you have a GPU\")\n",
        "    print(\"2. Ensure you have enough RAM/VRAM\")\n",
        "    print(\"3. Check your internet connection\")\n",
        "    \n",
        "# Alternative: Instructions for Llama 3.2\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"To use Llama 3.2 (recommended for better performance):\")\n",
        "print(\"1. Create a Hugging Face account at https://huggingface.co/\")\n",
        "print(\"2. Request access to the Llama 3.2 model\")\n",
        "print(\"3. Install huggingface_hub: pip install huggingface_hub\")\n",
        "print(\"4. Login: huggingface-cli login\")\n",
        "print(\"5. Then change model_name to 'meta-llama/Llama-3.2-1B'\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing the model with a sample question...\n",
            "Question: is it fine to exercise with knee pain?\n",
            "Generated Answer: Yes, you may want surgery if your knees get hurt during this time of year when they should be at their optimal level for healing or recovery from arthritis disease (arthritis). You can try not using any other medications as well but don't overdo them unless there is good evidence that taking antibiotics will heal all aspects in one day! For example, I have been suffering joint problems since early February so far which has made me feel better than ever before because my back hurts quite much more now after having an operation last week - especially considering how hard work goes on everyday here...\n",
            "\n",
            " I've tried multiple different drugs daily while trying various treatments including Tylenol's anti-inflammatory medication Seroquel Zoster/Cortisone; however\n",
            "---\n",
            "Generating answers for 20 questions...\n",
            "Processing question 1/20...\n",
            "Question: is it fine to exercise with knee pain?\n",
            "Generated Answer: Yes, you may want surgery if your knees get hurt during this time of year when they should be at their optimal level for healing or recovery from arthritis disease (arthritis). You can try not using any other medications as well but don't overdo them unless there is good evidence that taking antibiotics will heal all aspects in one day! For example, I have been suffering joint problems since early February so far which has made me feel better than ever before because my back hurts quite much more now after having an operation last week - especially considering how hard work goes on everyday here...\n",
            "\n",
            " I've tried multiple different drugs daily while trying various treatments including Tylenol's anti-inflammatory medication Seroquel Zoster/Cortisone; however\n",
            "---\n",
            "Generating answers for 20 questions...\n",
            "Processing question 1/20...\n",
            "Processing question 2/20...\n",
            "Processing question 2/20...\n",
            "Processing question 3/20...\n",
            "Processing question 3/20...\n",
            "Processing question 4/20...\n",
            "Processing question 4/20...\n",
            "Processing question 5/20...\n",
            "Processing question 5/20...\n",
            "Processing question 6/20...\n",
            "Processing question 6/20...\n",
            "Processing question 7/20...\n",
            "Processing question 7/20...\n",
            "Processing question 8/20...\n",
            "Processing question 8/20...\n",
            "Processing question 9/20...\n",
            "Processing question 9/20...\n",
            "Processing question 10/20...\n",
            "Processing question 10/20...\n",
            "Processing question 11/20...\n",
            "Processing question 11/20...\n",
            "Processing question 12/20...\n",
            "Processing question 12/20...\n",
            "Processing question 13/20...\n",
            "Processing question 13/20...\n",
            "Processing question 14/20...\n",
            "Processing question 14/20...\n",
            "Processing question 15/20...\n",
            "Processing question 15/20...\n",
            "Processing question 16/20...\n",
            "Processing question 16/20...\n",
            "Processing question 17/20...\n",
            "Processing question 17/20...\n",
            "Processing question 18/20...\n",
            "Processing question 18/20...\n",
            "Processing question 19/20...\n",
            "Processing question 19/20...\n",
            "Processing question 20/20...\n",
            "Processing question 20/20...\n",
            "Completed generating 20 answers!\n",
            "Completed generating 20 answers!\n"
          ]
        }
      ],
      "source": [
        "def ask_llama(model, tokenizer, question, max_new_tokens=150):\n",
        "    \"\"\"\n",
        "    Generate an answer to a medical question using Llama model\n",
        "    \"\"\"\n",
        "    # Create a more specific medical prompt\n",
        "    prompt = f\"\"\"You are a helpful medical assistant. Answer the following medical question concisely and accurately.\n",
        "\n",
        "Question: {question}\n",
        "Answer:\"\"\"\n",
        "    \n",
        "    try:\n",
        "        # Tokenize the input\n",
        "        input_ids = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "        \n",
        "        # Move to the same device as model\n",
        "        if hasattr(model, 'device'):\n",
        "            input_ids = {k: v.to(model.device) for k, v in input_ids.items()}\n",
        "        \n",
        "        # Generate response with better parameters\n",
        "        with torch.no_grad():\n",
        "            output_ids = model.generate(\n",
        "                **input_ids,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                do_sample=True,\n",
        "                temperature=0.7,\n",
        "                top_p=0.9,\n",
        "                pad_token_id=tokenizer.eos_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id,\n",
        "                repetition_penalty=1.1\n",
        "            )\n",
        "        \n",
        "        # Decode the response\n",
        "        generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "        \n",
        "        # Extract only the answer part\n",
        "        if \"Answer:\" in generated_text:\n",
        "            response = generated_text.split(\"Answer:\")[-1].strip()\n",
        "        else:\n",
        "            response = generated_text[len(prompt):].strip()\n",
        "        \n",
        "        return response\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error generating response for question: {question[:50]}...\")\n",
        "        print(f\"Error: {e}\")\n",
        "        return f\"Error: Could not generate response\"\n",
        "\n",
        "# Test the function with one sample\n",
        "if 'qa_samples' in locals() and len(qa_samples) > 0:\n",
        "    print(\"Testing the model with a sample question...\")\n",
        "    test_question = qa_samples[0]['question']\n",
        "    test_answer = ask_llama(model, tokenizer, test_question)\n",
        "    print(f\"Question: {test_question}\")\n",
        "    print(f\"Generated Answer: {test_answer}\")\n",
        "    print(\"---\")\n",
        "\n",
        "# Generate answers for all samples\n",
        "print(f\"Generating answers for {len(qa_samples)} questions...\")\n",
        "results = []\n",
        "\n",
        "for i, sample in enumerate(qa_samples):\n",
        "    print(f\"Processing question {i+1}/{len(qa_samples)}...\")\n",
        "    model_answer = ask_llama(model, tokenizer, sample['question'])\n",
        "    results.append({\n",
        "        'question': sample['question'], \n",
        "        'reference': sample['answer'], \n",
        "        'model_answer': model_answer\n",
        "    })\n",
        "\n",
        "print(f\"Completed generating {len(results)} answers!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU score over 20 samples: 0.004\n"
          ]
        }
      ],
      "source": [
        "bleu_scores = []\n",
        "for result in results:\n",
        "    ref = nltk.word_tokenize(result['reference'].lower())\n",
        "    candidate = nltk.word_tokenize(result['model_answer'].lower())\n",
        "    bleu_score = sentence_bleu([ref], candidate, smoothing_function=SmoothingFunction().method1)\n",
        "    bleu_scores.append(bleu_score)\n",
        "    \n",
        "avg_bleu = sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0\n",
        "print(f\"Average BLEU score over {len(results)} samples: {avg_bleu:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: is it fine to exercise with knee pain?\n",
            "Reference: from your description it appears that you may have anterior knee pain which sometimes presents as pain at the back of the knee. the second possibility is that you have over done your exercise and hamstrings are sore and the lower end of the knee cap is inflamed. either way you should rest and ice the area of pain and give it time. i suggest you add nsaids (nonsteroidal anti-inflammatory drugs) for a week for an additional anti-inflammatory action. for further information consult an orthopaedician and traumatologist online --> <link>\n",
            "Model Answer: It depends on your position, but if you do not feel discomfort or need for rest during that time then don't try this!\n",
            "BLEU: 0.00\n",
            "-----\n",
            "Question: suffering from anxiety restlessness and taking clonazepam & mirtazapine. i had depression & panic attacks for the last 7 years. need a second opinion.\n",
            "Reference: depression anxiety restlessness and panic attacks are best respond to a combination of a selective serotonin reuptake inhibitors (ssris) and benzodiazepines. mirtazapine is not the most efficient ant depressant and it is not a true ssri as fluoxetine paroxetine citalopram and sertraline are. i recommend 20 to 40mg of paroxetine (slowly titrated up from 10mg) and 1mg of either clonazepam or ativan (lorazepam) every 8 hours as needed for anxiety. glaucoma precludes use of any anticholinergics such as hydroxyzine or benadryl (diphenhydramine). ssris are also at times likely to make glaucoma worse but a preliminary trial is always worth it. revert back to a psychiatrist online for further help --> <link>\n",
            "Model Answer: This is my first experience with serotonin, dopamine, norepinephrine (N-methyl-D1aspartate), noradrenaline and other hormones that I have taken on or off during those past few weeks to relieve pain/panic when they can't take them anymore... My only problem was getting over it in time.. Also some people who use these drugs like me do not get relief anytime soon but many of us would rather be free than die at any moment because we did everything right so long ago.... Now you're going crazy! Reply Delete\n",
            "BLEU: 0.00\n",
            "-----\n",
            "Question: can a thyroid patient eat soybean and fenugreek?\n",
            "Reference: patients with hypothyroidism usually gain weight. your issue is weight loss which is seen in hyperthyroidism. as your thyroid tsh is in the normal range you can continue the same treatment. for gaining weight you need to take food which is adequate that is it should be rich in calorie and protein like eggs and green vegetables. kindly manage to take appropriate calories for your age and then have some physical activity so that it will increase your weight. for further information consult an internal medicine physician online --> <link>\n",
            "Model Answer: Soybeans (also called rice, beans or peas) contain high levels of both protein and fat in their seeds. Many people believe that eating these foods will help them achieve healthy weight because they have low amounts on average for all body types including men and women. The most common cause of illness with regard to this is overuse of artificial sweeteners by many consumers who try to avoid consuming such products due not knowing how much sugar there really has been found in those ingredients while also trying very hard NOT TO FOLLOW THE MIND OF YOUR OWN CHOICE! I would encourage you to follow your doctor's advice about using natural food as well so you don't make it into an unhealthy snack like peanut butter!! You know what happens when some doctors get sick\n",
            "BLEU: 0.00\n",
            "-----\n",
            "Question: i am not getting my periods after taking fenugreek seeds. why?\n",
            "Reference: fenugreek seed cannot affect your fertility do not worry. a delayed period could be because of stress or hormonal imbalance so please get a urine pregnancy test to rule out pregnancy first. for further queries consult an infertility specialist online --> <link>\n",
            "Model Answer: you have taken FENUGREE seed as well, but your period has been delayed by 5 weeks or so due to illness (as I do). The reason is that it causes more damage than if there was no issue with me eating them without any problems at all - in fact this makes an obvious difference! You should try using some other food for weight loss too because they may help decrease blood pressure slightly on short-term use of supplements like Fenuvia capsules .\n",
            "BLEU: 0.00\n",
            "-----\n",
            "Question: kindly suggest me a therapy to overcome heat allergy.\n",
            "Reference: your problem is a characteristic of cholinergic urticaria. it is a type of urticaria where patients are allergic to their own sweat. so whenever a patient sweats for example due to heat sun stress exercise. etc. the patient develops hives. levocetirizine can suppress the problem till you take it. once you stop taking it your problem will recur. the management actually depends on you. if you are fine taking cetirizine daily then no harm or else you can go for biological treatment which is a new form of treatment. it can permanently cure the problem and you may no longer require cetirizine. they are very safe with almost no side effect. for further information contact a dermatologist online --> <link>\n",
            "Model Answer: I have severe asthma that is causing my body to produce excessive amounts of sweat during sleep, which causes excruciating pain in both feet (a common side effect). This problem can be corrected by simply increasing your intake or using some type other non-sedative medication like cortisone for nausea/nauseas etc. You will feel better without it though because you know how painful this feeling actually becomes when taken as part \"in\" an exercise program with warm water on top. It helps reduce sweating so much while still being able keep up normal physical activity at night due just fine! If there's any doubt about whether hot air from outside should cause irritation then get help right away!! Also read our Hot Air Medicine blog here .\n",
            "\n",
            "   How\n",
            "BLEU: 0.01\n",
            "-----\n"
          ]
        }
      ],
      "source": [
        "for i, result in enumerate(results[:5]):\n",
        "    print(f\"Question: {result['question']}\")\n",
        "    print(f\"Reference: {result['reference']}\")\n",
        "    print(f\"Model Answer: {result['model_answer']}\")\n",
        "    print(f\"BLEU: {bleu_scores[i]:.2f}\")\n",
        "    print(\"-----\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "ZERO-SHOT MEDICAL QA EVALUATION RESULTS\n",
            "================================================================================\n",
            "\n",
            "Dataset: iCliniq Medical Q&A\n",
            "Model: gpt2\n",
            "Number of samples evaluated: 20\n",
            "Average BLEU Score: 0.0041\n",
            "\n",
            "Additional Metrics:\n",
            "Average model answer length: 112.2 words\n",
            "Average reference answer length: 139.1 words\n",
            "Average word overlap: 0.218\n",
            "\n",
            "BLEU Score Distribution:\n",
            "Min BLEU: 0.0007\n",
            "Max BLEU: 0.0073\n",
            "Median BLEU: 0.0038\n",
            "Std BLEU: 0.0017\n",
            "\n",
            "Note: Low BLEU scores are expected for GPT-2 on medical QA without fine-tuning.\n",
            "For better performance, consider:\n",
            "1. Using Llama 3.2 with proper authentication\n",
            "2. Fine-tuning the model on medical data\n",
            "3. Using few-shot prompting with medical examples\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "## Comprehensive Evaluation Summary\n",
        "\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ZERO-SHOT MEDICAL QA EVALUATION RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nDataset: iCliniq Medical Q&A\")\n",
        "print(f\"Model: {model_name}\")\n",
        "print(f\"Number of samples evaluated: {len(results)}\")\n",
        "print(f\"Average BLEU Score: {avg_bleu:.4f}\")\n",
        "\n",
        "# Additional metrics\n",
        "def calculate_additional_metrics(results):\n",
        "    answer_lengths = []\n",
        "    reference_lengths = []\n",
        "    overlap_scores = []\n",
        "    \n",
        "    for result in results:\n",
        "        # Calculate answer lengths\n",
        "        model_words = len(result['model_answer'].split())\n",
        "        ref_words = len(result['reference'].split())\n",
        "        answer_lengths.append(model_words)\n",
        "        reference_lengths.append(ref_words)\n",
        "        \n",
        "        # Calculate word overlap\n",
        "        model_words_set = set(result['model_answer'].lower().split())\n",
        "        ref_words_set = set(result['reference'].lower().split())\n",
        "        if len(ref_words_set) > 0:\n",
        "            overlap = len(model_words_set.intersection(ref_words_set)) / len(ref_words_set)\n",
        "            overlap_scores.append(overlap)\n",
        "        else:\n",
        "            overlap_scores.append(0)\n",
        "    \n",
        "    return answer_lengths, reference_lengths, overlap_scores\n",
        "\n",
        "answer_lengths, reference_lengths, overlap_scores = calculate_additional_metrics(results)\n",
        "\n",
        "print(f\"\\nAdditional Metrics:\")\n",
        "print(f\"Average model answer length: {np.mean(answer_lengths):.1f} words\")\n",
        "print(f\"Average reference answer length: {np.mean(reference_lengths):.1f} words\")\n",
        "print(f\"Average word overlap: {np.mean(overlap_scores):.3f}\")\n",
        "\n",
        "# Show distribution of BLEU scores\n",
        "print(f\"\\nBLEU Score Distribution:\")\n",
        "print(f\"Min BLEU: {min(bleu_scores):.4f}\")\n",
        "print(f\"Max BLEU: {max(bleu_scores):.4f}\")\n",
        "print(f\"Median BLEU: {np.median(bleu_scores):.4f}\")\n",
        "print(f\"Std BLEU: {np.std(bleu_scores):.4f}\")\n",
        "\n",
        "print(f\"\\nNote: Low BLEU scores are expected for GPT-2 on medical QA without fine-tuning.\")\n",
        "print(f\"For better performance, consider:\")\n",
        "print(f\"1. Using Llama 3.2 with proper authentication\")\n",
        "print(f\"2. Fine-tuning the model on medical data\")\n",
        "print(f\"3. Using few-shot prompting with medical examples\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "RAGSystem",
      "language": "python",
      "name": "ragsystem"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
